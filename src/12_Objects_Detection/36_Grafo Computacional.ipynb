{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1LznRAQeGhXIqaVovYj6uJ-ZU3pFPgkEM","timestamp":1699883167333}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VmSu9ZCgoVD1"},"source":["\n","\n","\n","\n","# Grafo Computacional"]},{"cell_type":"code","metadata":{"id":"ltMXNKQBoeoD"},"source":["!pip install torchviz\n","import torch\n","from torch import nn\n","from torchviz import make_dot, make_dot_from_trace"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2FanecKKoVD4"},"source":["## Sumando dos vectores\n","\n","En este ejemplo sumamos 2 vectores del mismo tamaño: x e y. Vemos el grafo computacional de z = x+ y"]},{"cell_type":"code","metadata":{"id":"Eve8Pt81q5ho"},"source":["x = torch.randn(3, requires_grad=True)\n","y = torch.randn(3, requires_grad=True)\n","print(x, y)\n","z = x+y\n","params={'x':x, 'y':y, 'z':z}\n","print(z)\n","make_dot(z, params)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wlizFk_8wUAZ"},"source":["## Acumulando valores en un loop\n","\n","En este ejemplo acumulamos valores en un loop"]},{"cell_type":"code","metadata":{"id":"Vm8KbZ5ZoVD5"},"source":["x = torch.zeros(3, requires_grad=True)\n","y = torch.ones(3, requires_grad=True)\n","params={'x':x, 'y':y}\n","for i in range(10):\n","  x = x+y\n","print(x)\n","make_dot(x, params)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nw_ZuMo21TOL"},"source":["def cuadrado(x):\n","  return x*x\n","x = torch.zeros(1, requires_grad=True)\n","z = cuadrado(cuadrado(cuadrado(x)))\n","params={'z':z, 'x':x}\n","print(z)\n","make_dot(z, params)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q8TddKbyyr0Q"},"source":["## Diferenciación automática"]},{"cell_type":"code","metadata":{"id":"auNxe7MdMDS_"},"source":["import torch\n","from torch.autograd import grad\n","\n","x1 = torch.tensor(2, requires_grad=True, dtype=torch.float32)\n","x2 = torch.tensor(3, requires_grad=True, dtype=torch.float32)\n","x3 = torch.tensor(1, requires_grad=True, dtype=torch.float32)\n","x4 = torch.tensor(4, requires_grad=True, dtype=torch.float32)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PCt1qF1PzTuQ"},"source":["### Operaciones"]},{"cell_type":"code","metadata":{"id":"QEe9O_j-y984"},"source":["z1 = x1*x2\n","z2 = x3*x4\n","f = z1 + z2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fdqGxhYXzXUW"},"source":["### Calculando gradiente (derivadas parciales)"]},{"cell_type":"code","metadata":{"id":"XLsKYJFtzHxf"},"source":["df_dx = grad(outputs=f, inputs=[x1,x2,x3,x4])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vJT4iE6DzcJc"},"source":["print(\"Gradiente de x1 = {}\".format(df_dx[0]))\n","print(\"Gradiente de x2 = {}\".format(df_dx[1]))\n","print(\"Gradiente de x3 = {}\".format(df_dx[2]))\n","print(\"Gradiente de x4 = {}\".format(df_dx[3]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Qnm3mQPA2sJc"},"source":["Sin embargo, esto es poco conveniente..."]},{"cell_type":"code","metadata":{"id":"NFeWtcgozpP-"},"source":["z1 = x1*x2\n","z2 = x3*x4\n","f = z1 + z2\n","\n","f.backward()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rrjANe392pch"},"source":["print(\"Gradiente de x1 = {}\".format(x1.grad))\n","print(\"Gradiente de x2 = {}\".format(x2.grad))\n","print(\"Gradiente de x3 = {}\".format(x3.grad))\n","print(\"Gradiente de x4 = {}\".format(x4.grad))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Do7fcIs4I2m-"},"source":[],"execution_count":null,"outputs":[]}]}